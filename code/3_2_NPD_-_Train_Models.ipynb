{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py37torch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/anaconda/envs/py37torch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/anaconda/envs/py37torch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/anaconda/envs/py37torch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/anaconda/envs/py37torch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/anaconda/envs/py37torch/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# load the classes and function for processing the NPDs\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import dill\n",
    "#import tools.load\n",
    "from tools.helpers import range_to_pagenumbers\n",
    "import pycrfsuite\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tools.collection_tools import Collection\n",
    "from tools.crf_tools import SequenceVectorizer\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "import flair\n",
    "from flair.embeddings import *\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.datasets import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path('/deezy_datadrive/kaspar-playground/npd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = ROOT / 'Data'\n",
    "IN_PATH = ROOT / DATA / \"Original\"\n",
    "OUT_PATH = ROOT /  DATA / \"Processed\"\n",
    "MODELS_PATH = ROOT / 'Models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "editions_all = pickle.load(open('../editions_all.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_years = [int(p.name.split(\"_\")[1]) for p in list(IN_PATH.glob('MPD_*'))]\n",
    "editions = {y:editions_all[y] for y in selected_years}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "editions = range_to_pagenumbers(editions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 'structure' # structure | lemmas \n",
    "clip_bioes = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare corpus for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 162 181\n",
      "structure\n"
     ]
    }
   ],
   "source": [
    "npd_collection = Collection(editions,IN_PATH,OUT_PATH)\n",
    " \n",
    "if level == 'structure': \n",
    "    clip_bioes = True\n",
    "    \n",
    "npd_collection.create_csv_training_data(MODELS_PATH,train_perc=.8,dev_perc=.1,\n",
    "                                        level=level, clip_bioes=clip_bioes) # # ,recode=recode[level]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-12 09:15:44,441 Reading data from /deezy_datadrive/kaspar-playground/npd/Models\n",
      "2021-03-12 09:15:44,441 Train: /deezy_datadrive/kaspar-playground/npd/Models/train_structure.csv\n",
      "2021-03-12 09:15:44,442 Dev: /deezy_datadrive/kaspar-playground/npd/Models/dev_structure.csv\n",
      "2021-03-12 09:15:44,442 Test: /deezy_datadrive/kaspar-playground/npd/Models/test_structure.csv\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "columns = {0: 'text', 1: level} \n",
    "corpus: Corpus = ColumnCorpus(MODELS_PATH, columns,\n",
    "                              train_file=MODELS_PATH / f'train_{level}.csv',\n",
    "                              test_file=MODELS_PATH /f'test_{level}.csv',\n",
    "                              dev_file=MODELS_PATH / f'dev_{level}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-12 09:15:49,288 Filtering empty sentences\n",
      "2021-03-12 09:15:49,290 Corpus: 144 train + 18 dev + 19 test sentences\n",
      "Corpus: 144 train + 18 dev + 19 test sentences\n",
      "[b'<unk>', b'O', b'NEWSPAPERDESCR', b'TITLE', b'LOC', b'LOCDESCR', b'HEADER', b'<START>', b'<STOP>']\n"
     ]
    }
   ],
   "source": [
    "corpus.filter_empty_sentences()\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=level)\n",
    "print(corpus)\n",
    "print(tag_dictionary.idx2item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = None\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device('cuda:0')\n",
    "#else:\n",
    "#    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flair.device = torch.device('cuda:0') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if level == 'structure':\n",
    "    embedding_types = [\n",
    "        #FlairEmbeddings('en-impresso-hipe-v1-forward'), # en-impresso-hipe-v1-forward news-forward\n",
    "        FlairEmbeddings('news-forward'),\n",
    "        #FlairEmbeddings('en-impresso-hipe-v1-backward'), # 'news-backward'\n",
    "        FlairEmbeddings('news-backward'),\n",
    "        WordEmbeddings('glove'),\n",
    "        ]\n",
    "    \n",
    "    embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "    #embeddings = TransformerWordEmbeddings('bert-base-cased', \n",
    "    #                                        fine_tune=True,\n",
    "    #                                        layers='-1',\n",
    "    #                                        pooling_operation='mean',\n",
    "    #                                        allow_long_sentences=True)\n",
    "elif level == \"lemmas\":\n",
    "    embeddings = TransformerWordEmbeddings('bert-base-cased',fine_tune=True, allow_long_sentences=True,pooling_operation='mean',)\n",
    "    #embedding_types = [\n",
    "    #    FlairEmbeddings('news-forward'),\n",
    "    #    FlairEmbeddings('news-backward'),\n",
    "    #    WordEmbeddings('glove'),\n",
    "    #    ]\n",
    "    #embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "\n",
    "    #embeddings = TransformerWordEmbeddings('bert-base-cased', \n",
    "    #                                        fine_tune=True,\n",
    "    #                                        layers='-1',\n",
    "    #                                        \n",
    "    #                                        allow_long_sentences=True)\n",
    "else:\n",
    "    raise Exception(\"Selet either structure or lemmas as level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if level == 'structure':\n",
    "    loss_weights = {'LOC': 5., 'TITLE':5.}\n",
    "else:\n",
    "    loss_weights = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = SequenceTagger(hidden_size=128,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=tag_dictionary,\n",
    "                        tag_type=level,\n",
    "                        use_crf=True,\n",
    "                        loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-12 09:15:50,912 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:15:50,915 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.05, inplace=False)\n",
      "        (encoder): Embedding(300, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): WordEmbeddings('glove')\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
      "  (rnn): LSTM(4196, 128, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=256, out_features=9, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): {'LOC': 5.0, 'TITLE': 5.0}\n",
      "  (weight_tensor) tensor([1., 1., 1., 5., 5., 1., 1., 1., 1.], device='cuda:0')\n",
      ")\"\n",
      "2021-03-12 09:15:50,916 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:15:50,916 Corpus: \"Corpus: 144 train + 18 dev + 19 test sentences\"\n",
      "2021-03-12 09:15:50,917 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:15:50,917 Parameters:\n",
      "2021-03-12 09:15:50,917  - learning_rate: \"0.05\"\n",
      "2021-03-12 09:15:50,918  - mini_batch_size: \"4\"\n",
      "2021-03-12 09:15:50,918  - patience: \"2\"\n",
      "2021-03-12 09:15:50,919  - anneal_factor: \"0.5\"\n",
      "2021-03-12 09:15:50,919  - max_epochs: \"10\"\n",
      "2021-03-12 09:15:50,920  - shuffle: \"True\"\n",
      "2021-03-12 09:15:50,920  - train_with_dev: \"False\"\n",
      "2021-03-12 09:15:50,921  - batch_growth_annealing: \"False\"\n",
      "2021-03-12 09:15:50,921 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:15:50,921 Model training base path: \"/deezy_datadrive/kaspar-playground/npd/Models/structure_tagger\"\n",
      "2021-03-12 09:15:50,922 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:15:50,922 Device: cuda:0\n",
      "2021-03-12 09:15:50,923 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:15:50,923 Embeddings storage mode: cpu\n",
      "2021-03-12 09:15:50,924 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:15:50,924 WARNING: Specified class weights will not take effect when using CRF\n",
      "2021-03-12 09:15:50,927 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:16:41,477 epoch 1 - iter 3/36 - loss 3587.85359701 - samples/sec: 0.24 - lr: 0.050000\n",
      "2021-03-12 09:17:29,923 epoch 1 - iter 6/36 - loss 2832.70884196 - samples/sec: 0.25 - lr: 0.050000\n",
      "2021-03-12 09:18:18,813 epoch 1 - iter 9/36 - loss 2446.58171929 - samples/sec: 0.25 - lr: 0.050000\n",
      "2021-03-12 09:19:06,699 epoch 1 - iter 12/36 - loss 2174.88839722 - samples/sec: 0.25 - lr: 0.050000\n",
      "2021-03-12 09:19:57,294 epoch 1 - iter 15/36 - loss 2083.04995117 - samples/sec: 0.24 - lr: 0.050000\n",
      "2021-03-12 09:20:47,975 epoch 1 - iter 18/36 - loss 1974.42192925 - samples/sec: 0.24 - lr: 0.050000\n",
      "2021-03-12 09:21:38,672 epoch 1 - iter 21/36 - loss 1853.90496826 - samples/sec: 0.24 - lr: 0.050000\n",
      "2021-03-12 09:25:01,815 epoch 1 - iter 33/36 - loss 1557.95163981 - samples/sec: 0.23 - lr: 0.050000\n",
      "2021-03-12 09:25:48,988 epoch 1 - iter 36/36 - loss 1521.80278015 - samples/sec: 0.25 - lr: 0.050000\n",
      "2021-03-12 09:25:48,989 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:25:48,989 EPOCH 1 done: loss 1521.8028 - lr 0.0500000\n",
      "2021-03-12 09:26:51,390 DEV : loss 781.734375 - score 0.7984\n",
      "2021-03-12 09:27:58,566 TEST : loss 766.4435424804688 - score 0.8085\n",
      "2021-03-12 09:27:58,704 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-12 09:28:02,202 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:28:19,194 epoch 2 - iter 3/36 - loss 1218.58083089 - samples/sec: 0.71 - lr: 0.050000\n",
      "2021-03-12 09:28:33,664 epoch 2 - iter 6/36 - loss 1049.26286825 - samples/sec: 0.83 - lr: 0.050000\n",
      "2021-03-12 09:28:48,121 epoch 2 - iter 9/36 - loss 995.65192329 - samples/sec: 0.83 - lr: 0.050000\n",
      "2021-03-12 09:29:01,905 epoch 2 - iter 12/36 - loss 934.50204976 - samples/sec: 0.87 - lr: 0.050000\n",
      "2021-03-12 09:29:15,816 epoch 2 - iter 15/36 - loss 896.82639160 - samples/sec: 0.86 - lr: 0.050000\n",
      "2021-03-12 09:29:30,418 epoch 2 - iter 18/36 - loss 950.55203586 - samples/sec: 0.82 - lr: 0.050000\n",
      "2021-03-12 09:29:44,909 epoch 2 - iter 21/36 - loss 925.09323265 - samples/sec: 0.83 - lr: 0.050000\n",
      "2021-03-12 09:29:59,259 epoch 2 - iter 24/36 - loss 893.92537435 - samples/sec: 0.84 - lr: 0.050000\n",
      "2021-03-12 09:30:13,345 epoch 2 - iter 27/36 - loss 868.37919108 - samples/sec: 0.85 - lr: 0.050000\n",
      "2021-03-12 09:30:27,995 epoch 2 - iter 30/36 - loss 843.52817790 - samples/sec: 0.82 - lr: 0.050000\n",
      "2021-03-12 09:30:43,227 epoch 2 - iter 33/36 - loss 818.54364938 - samples/sec: 0.79 - lr: 0.050000\n",
      "2021-03-12 09:30:57,996 epoch 2 - iter 36/36 - loss 790.87848070 - samples/sec: 0.81 - lr: 0.050000\n",
      "2021-03-12 09:30:57,997 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:30:57,998 EPOCH 2 done: loss 790.8785 - lr 0.0500000\n",
      "2021-03-12 09:31:07,930 DEV : loss 574.2696533203125 - score 0.773\n",
      "2021-03-12 09:31:17,458 TEST : loss 547.9555053710938 - score 0.7916\n",
      "2021-03-12 09:31:17,620 BAD EPOCHS (no improvement): 1\n",
      "2021-03-12 09:31:17,621 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:31:33,324 epoch 3 - iter 3/36 - loss 638.31666056 - samples/sec: 0.76 - lr: 0.050000\n",
      "2021-03-12 09:31:50,470 epoch 3 - iter 6/36 - loss 587.62060547 - samples/sec: 0.70 - lr: 0.050000\n",
      "2021-03-12 09:32:05,450 epoch 3 - iter 9/36 - loss 737.49705675 - samples/sec: 0.80 - lr: 0.050000\n",
      "2021-03-12 09:32:20,991 epoch 3 - iter 12/36 - loss 750.72915141 - samples/sec: 0.77 - lr: 0.050000\n",
      "2021-03-12 09:32:35,287 epoch 3 - iter 15/36 - loss 712.89045817 - samples/sec: 0.84 - lr: 0.050000\n",
      "2021-03-12 09:32:49,901 epoch 3 - iter 18/36 - loss 700.10805257 - samples/sec: 0.82 - lr: 0.050000\n",
      "2021-03-12 09:33:06,230 epoch 3 - iter 21/36 - loss 671.99912226 - samples/sec: 0.73 - lr: 0.050000\n",
      "2021-03-12 09:33:21,023 epoch 3 - iter 24/36 - loss 676.08224360 - samples/sec: 0.81 - lr: 0.050000\n",
      "2021-03-12 09:33:36,310 epoch 3 - iter 27/36 - loss 674.59137528 - samples/sec: 0.79 - lr: 0.050000\n",
      "2021-03-12 09:33:50,365 epoch 3 - iter 30/36 - loss 638.73084615 - samples/sec: 0.85 - lr: 0.050000\n",
      "2021-03-12 09:34:04,688 epoch 3 - iter 33/36 - loss 612.85415742 - samples/sec: 0.84 - lr: 0.050000\n",
      "2021-03-12 09:34:19,679 epoch 3 - iter 36/36 - loss 592.73329163 - samples/sec: 0.80 - lr: 0.050000\n",
      "2021-03-12 09:34:19,680 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:34:19,681 EPOCH 3 done: loss 592.7333 - lr 0.0500000\n",
      "2021-03-12 09:34:28,422 DEV : loss 351.059814453125 - score 0.8169\n",
      "2021-03-12 09:34:37,712 TEST : loss 367.0103454589844 - score 0.8265\n",
      "2021-03-12 09:34:37,857 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-12 09:34:41,482 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:34:56,626 epoch 4 - iter 3/36 - loss 409.51440430 - samples/sec: 0.79 - lr: 0.050000\n",
      "2021-03-12 09:35:12,816 epoch 4 - iter 6/36 - loss 525.81163025 - samples/sec: 0.74 - lr: 0.050000\n",
      "2021-03-12 09:35:29,045 epoch 4 - iter 9/36 - loss 547.81769816 - samples/sec: 0.74 - lr: 0.050000\n",
      "2021-03-12 09:35:43,270 epoch 4 - iter 12/36 - loss 534.51924896 - samples/sec: 0.84 - lr: 0.050000\n",
      "2021-03-12 09:35:58,302 epoch 4 - iter 15/36 - loss 569.15649618 - samples/sec: 0.80 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-12 09:36:13,660 epoch 4 - iter 18/36 - loss 568.97229852 - samples/sec: 0.78 - lr: 0.050000\n",
      "2021-03-12 09:36:28,956 epoch 4 - iter 21/36 - loss 560.25790696 - samples/sec: 0.78 - lr: 0.050000\n",
      "2021-03-12 09:36:44,396 epoch 4 - iter 24/36 - loss 531.59891001 - samples/sec: 0.78 - lr: 0.050000\n",
      "2021-03-12 09:36:58,599 epoch 4 - iter 27/36 - loss 517.12264789 - samples/sec: 0.84 - lr: 0.050000\n",
      "2021-03-12 09:37:11,955 epoch 4 - iter 30/36 - loss 497.18141174 - samples/sec: 0.90 - lr: 0.050000\n",
      "2021-03-12 09:37:27,062 epoch 4 - iter 33/36 - loss 484.02090084 - samples/sec: 0.79 - lr: 0.050000\n",
      "2021-03-12 09:37:42,211 epoch 4 - iter 36/36 - loss 469.07271576 - samples/sec: 0.79 - lr: 0.050000\n",
      "2021-03-12 09:37:42,212 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:37:42,212 EPOCH 4 done: loss 469.0727 - lr 0.0500000\n",
      "2021-03-12 09:37:50,861 DEV : loss 195.12217712402344 - score 0.9162\n",
      "2021-03-12 09:38:00,198 TEST : loss 239.26866149902344 - score 0.9244\n",
      "2021-03-12 09:38:00,343 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-12 09:38:03,855 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:38:19,575 epoch 5 - iter 3/36 - loss 195.74334717 - samples/sec: 0.76 - lr: 0.050000\n",
      "2021-03-12 09:38:37,214 epoch 5 - iter 6/36 - loss 221.53520711 - samples/sec: 0.68 - lr: 0.050000\n",
      "2021-03-12 09:38:53,409 epoch 5 - iter 9/36 - loss 335.98232015 - samples/sec: 0.74 - lr: 0.050000\n",
      "2021-03-12 09:39:08,497 epoch 5 - iter 12/36 - loss 411.78894297 - samples/sec: 0.80 - lr: 0.050000\n",
      "2021-03-12 09:39:24,053 epoch 5 - iter 15/36 - loss 441.63460490 - samples/sec: 0.77 - lr: 0.050000\n",
      "2021-03-12 09:39:40,737 epoch 5 - iter 18/36 - loss 445.78055149 - samples/sec: 0.72 - lr: 0.050000\n",
      "2021-03-12 09:39:55,858 epoch 5 - iter 21/36 - loss 461.97112165 - samples/sec: 0.79 - lr: 0.050000\n",
      "2021-03-12 09:40:11,697 epoch 5 - iter 24/36 - loss 463.75249736 - samples/sec: 0.76 - lr: 0.050000\n",
      "2021-03-12 09:40:28,806 epoch 5 - iter 27/36 - loss 439.30707917 - samples/sec: 0.70 - lr: 0.050000\n",
      "2021-03-12 09:40:44,474 epoch 5 - iter 30/36 - loss 444.78446960 - samples/sec: 0.77 - lr: 0.050000\n",
      "2021-03-12 09:40:57,915 epoch 5 - iter 33/36 - loss 431.53293124 - samples/sec: 0.89 - lr: 0.050000\n",
      "2021-03-12 09:41:12,702 epoch 5 - iter 36/36 - loss 420.64281718 - samples/sec: 0.81 - lr: 0.050000\n",
      "2021-03-12 09:41:12,703 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:41:12,703 EPOCH 5 done: loss 420.6428 - lr 0.0500000\n",
      "2021-03-12 09:41:21,458 DEV : loss 176.9423828125 - score 0.9182\n",
      "2021-03-12 09:41:30,808 TEST : loss 221.69558715820312 - score 0.9227\n",
      "2021-03-12 09:41:30,954 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-12 09:41:34,489 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:41:49,181 epoch 6 - iter 3/36 - loss 528.30920410 - samples/sec: 0.82 - lr: 0.050000\n",
      "2021-03-12 09:42:04,430 epoch 6 - iter 6/36 - loss 463.27542114 - samples/sec: 0.79 - lr: 0.050000\n",
      "2021-03-12 09:42:18,557 epoch 6 - iter 9/36 - loss 384.32566325 - samples/sec: 0.85 - lr: 0.050000\n",
      "2021-03-12 09:42:33,433 epoch 6 - iter 12/36 - loss 363.31673177 - samples/sec: 0.81 - lr: 0.050000\n",
      "2021-03-12 09:42:48,767 epoch 6 - iter 15/36 - loss 337.52744344 - samples/sec: 0.78 - lr: 0.050000\n",
      "2021-03-12 09:43:04,012 epoch 6 - iter 18/36 - loss 387.75057814 - samples/sec: 0.79 - lr: 0.050000\n",
      "2021-03-12 09:43:17,924 epoch 6 - iter 21/36 - loss 373.27187820 - samples/sec: 0.86 - lr: 0.050000\n",
      "2021-03-12 09:43:32,410 epoch 6 - iter 24/36 - loss 375.31056595 - samples/sec: 0.83 - lr: 0.050000\n",
      "2021-03-12 09:43:47,142 epoch 6 - iter 27/36 - loss 358.63500864 - samples/sec: 0.81 - lr: 0.050000\n",
      "2021-03-12 09:44:01,331 epoch 6 - iter 30/36 - loss 350.56436971 - samples/sec: 0.85 - lr: 0.050000\n",
      "2021-03-12 09:44:15,986 epoch 6 - iter 33/36 - loss 356.60640925 - samples/sec: 0.82 - lr: 0.050000\n",
      "2021-03-12 09:44:29,672 epoch 6 - iter 36/36 - loss 343.20276811 - samples/sec: 0.88 - lr: 0.050000\n",
      "2021-03-12 09:44:29,672 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:44:29,673 EPOCH 6 done: loss 343.2028 - lr 0.0500000\n",
      "2021-03-12 09:44:38,297 DEV : loss 179.46585083007812 - score 0.9147\n",
      "2021-03-12 09:44:47,621 TEST : loss 218.51904296875 - score 0.9141\n",
      "2021-03-12 09:44:47,766 BAD EPOCHS (no improvement): 1\n",
      "2021-03-12 09:44:47,767 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:45:02,103 epoch 7 - iter 3/36 - loss 270.81941732 - samples/sec: 0.84 - lr: 0.050000\n",
      "2021-03-12 09:45:17,825 epoch 7 - iter 6/36 - loss 235.68565369 - samples/sec: 0.76 - lr: 0.050000\n",
      "2021-03-12 09:45:33,011 epoch 7 - iter 9/36 - loss 258.52812025 - samples/sec: 0.79 - lr: 0.050000\n",
      "2021-03-12 09:45:48,410 epoch 7 - iter 12/36 - loss 253.76048024 - samples/sec: 0.78 - lr: 0.050000\n",
      "2021-03-12 09:46:03,448 epoch 7 - iter 15/36 - loss 258.75887248 - samples/sec: 0.80 - lr: 0.050000\n",
      "2021-03-12 09:46:17,798 epoch 7 - iter 18/36 - loss 278.29892476 - samples/sec: 0.84 - lr: 0.050000\n",
      "2021-03-12 09:46:32,687 epoch 7 - iter 21/36 - loss 268.38617961 - samples/sec: 0.81 - lr: 0.050000\n",
      "2021-03-12 09:46:47,256 epoch 7 - iter 24/36 - loss 282.44268926 - samples/sec: 0.82 - lr: 0.050000\n",
      "2021-03-12 09:47:03,634 epoch 7 - iter 27/36 - loss 318.60582931 - samples/sec: 0.73 - lr: 0.050000\n",
      "2021-03-12 09:47:20,179 epoch 7 - iter 30/36 - loss 336.95306702 - samples/sec: 0.73 - lr: 0.050000\n",
      "2021-03-12 09:47:35,442 epoch 7 - iter 33/36 - loss 342.07492158 - samples/sec: 0.79 - lr: 0.050000\n",
      "2021-03-12 09:47:52,142 epoch 7 - iter 36/36 - loss 332.59076945 - samples/sec: 0.72 - lr: 0.050000\n",
      "2021-03-12 09:47:52,143 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:47:52,143 EPOCH 7 done: loss 332.5908 - lr 0.0500000\n",
      "2021-03-12 09:48:00,886 DEV : loss 106.96636199951172 - score 0.9729\n",
      "2021-03-12 09:48:10,227 TEST : loss 152.3429718017578 - score 0.9577\n",
      "2021-03-12 09:48:10,372 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-12 09:48:13,987 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:48:29,763 epoch 8 - iter 3/36 - loss 202.37980143 - samples/sec: 0.76 - lr: 0.050000\n",
      "2021-03-12 09:48:45,124 epoch 8 - iter 6/36 - loss 204.86193848 - samples/sec: 0.78 - lr: 0.050000\n",
      "2021-03-12 09:49:00,743 epoch 8 - iter 9/36 - loss 193.18260023 - samples/sec: 0.77 - lr: 0.050000\n",
      "2021-03-12 09:49:15,513 epoch 8 - iter 12/36 - loss 195.41775258 - samples/sec: 0.81 - lr: 0.050000\n",
      "2021-03-12 09:49:30,909 epoch 8 - iter 15/36 - loss 193.12122192 - samples/sec: 0.78 - lr: 0.050000\n",
      "2021-03-12 09:49:45,888 epoch 8 - iter 18/36 - loss 182.80350579 - samples/sec: 0.80 - lr: 0.050000\n",
      "2021-03-12 09:50:01,583 epoch 8 - iter 21/36 - loss 245.70144944 - samples/sec: 0.76 - lr: 0.050000\n",
      "2021-03-12 09:50:15,937 epoch 8 - iter 24/36 - loss 261.08863449 - samples/sec: 0.84 - lr: 0.050000\n",
      "2021-03-12 09:50:31,262 epoch 8 - iter 27/36 - loss 260.38544153 - samples/sec: 0.78 - lr: 0.050000\n",
      "2021-03-12 09:50:45,605 epoch 8 - iter 30/36 - loss 267.69825643 - samples/sec: 0.84 - lr: 0.050000\n",
      "2021-03-12 09:51:00,869 epoch 8 - iter 33/36 - loss 276.25715961 - samples/sec: 0.79 - lr: 0.050000\n",
      "2021-03-12 09:51:17,217 epoch 8 - iter 36/36 - loss 281.66776360 - samples/sec: 0.73 - lr: 0.050000\n",
      "2021-03-12 09:51:17,218 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:51:17,219 EPOCH 8 done: loss 281.6678 - lr 0.0500000\n",
      "2021-03-12 09:51:25,872 DEV : loss 104.02349090576172 - score 0.9673\n",
      "2021-03-12 09:51:36,514 TEST : loss 132.98855590820312 - score 0.9552\n",
      "2021-03-12 09:51:36,692 BAD EPOCHS (no improvement): 1\n",
      "2021-03-12 09:51:36,693 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:51:52,574 epoch 9 - iter 3/36 - loss 194.16446940 - samples/sec: 0.76 - lr: 0.050000\n",
      "2021-03-12 09:52:08,436 epoch 9 - iter 6/36 - loss 160.46900431 - samples/sec: 0.76 - lr: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-12 09:52:22,995 epoch 9 - iter 9/36 - loss 162.14892578 - samples/sec: 0.82 - lr: 0.050000\n",
      "2021-03-12 09:52:38,812 epoch 9 - iter 12/36 - loss 273.79946645 - samples/sec: 0.76 - lr: 0.050000\n",
      "2021-03-12 09:52:53,262 epoch 9 - iter 15/36 - loss 258.29253540 - samples/sec: 0.83 - lr: 0.050000\n",
      "2021-03-12 09:53:08,005 epoch 9 - iter 18/36 - loss 238.05364821 - samples/sec: 0.81 - lr: 0.050000\n",
      "2021-03-12 09:53:23,668 epoch 9 - iter 21/36 - loss 322.30877250 - samples/sec: 0.77 - lr: 0.050000\n",
      "2021-03-12 09:53:38,057 epoch 9 - iter 24/36 - loss 313.81995773 - samples/sec: 0.83 - lr: 0.050000\n",
      "2021-03-12 09:53:53,543 epoch 9 - iter 27/36 - loss 308.45786427 - samples/sec: 0.77 - lr: 0.050000\n",
      "2021-03-12 09:54:09,208 epoch 9 - iter 30/36 - loss 313.83685404 - samples/sec: 0.77 - lr: 0.050000\n",
      "2021-03-12 09:54:26,209 epoch 9 - iter 33/36 - loss 303.01778620 - samples/sec: 0.71 - lr: 0.050000\n",
      "2021-03-12 09:54:42,679 epoch 9 - iter 36/36 - loss 296.88750627 - samples/sec: 0.73 - lr: 0.050000\n",
      "2021-03-12 09:54:42,680 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:54:42,681 EPOCH 9 done: loss 296.8875 - lr 0.0500000\n",
      "2021-03-12 09:54:51,295 DEV : loss 85.7772445678711 - score 0.9764\n",
      "2021-03-12 09:55:00,522 TEST : loss 132.01219177246094 - score 0.9704\n",
      "2021-03-12 09:55:00,669 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-12 09:55:04,185 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:55:19,858 epoch 10 - iter 3/36 - loss 159.42364502 - samples/sec: 0.77 - lr: 0.050000\n",
      "2021-03-12 09:55:36,550 epoch 10 - iter 6/36 - loss 268.39049276 - samples/sec: 0.72 - lr: 0.050000\n",
      "2021-03-12 09:55:54,067 epoch 10 - iter 9/36 - loss 308.33557807 - samples/sec: 0.69 - lr: 0.050000\n",
      "2021-03-12 09:56:08,815 epoch 10 - iter 12/36 - loss 343.16999308 - samples/sec: 0.81 - lr: 0.050000\n",
      "2021-03-12 09:56:24,383 epoch 10 - iter 15/36 - loss 343.00043538 - samples/sec: 0.77 - lr: 0.050000\n",
      "2021-03-12 09:56:40,239 epoch 10 - iter 18/36 - loss 314.07788086 - samples/sec: 0.76 - lr: 0.050000\n",
      "2021-03-12 09:56:56,115 epoch 10 - iter 21/36 - loss 292.85508801 - samples/sec: 0.76 - lr: 0.050000\n",
      "2021-03-12 09:57:10,898 epoch 10 - iter 24/36 - loss 272.68285370 - samples/sec: 0.81 - lr: 0.050000\n",
      "2021-03-12 09:57:26,350 epoch 10 - iter 27/36 - loss 254.70169180 - samples/sec: 0.78 - lr: 0.050000\n",
      "2021-03-12 09:57:40,070 epoch 10 - iter 30/36 - loss 240.33156738 - samples/sec: 0.87 - lr: 0.050000\n",
      "2021-03-12 09:57:54,979 epoch 10 - iter 33/36 - loss 230.26453746 - samples/sec: 0.80 - lr: 0.050000\n",
      "2021-03-12 09:58:09,309 epoch 10 - iter 36/36 - loss 236.19796583 - samples/sec: 0.84 - lr: 0.050000\n",
      "2021-03-12 09:58:09,310 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:58:09,310 EPOCH 10 done: loss 236.1980 - lr 0.0500000\n",
      "2021-03-12 09:58:17,955 DEV : loss 81.4693603515625 - score 0.9816\n",
      "2021-03-12 09:58:27,219 TEST : loss 123.3783187866211 - score 0.9735\n",
      "2021-03-12 09:58:27,366 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-12 09:58:38,000 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-12 09:58:38,001 Testing using best model ...\n",
      "2021-03-12 09:58:38,002 loading file /deezy_datadrive/kaspar-playground/npd/Models/structure_tagger/best-model.pt\n",
      "2021-03-12 09:58:49,549 \t0.9735\n",
      "2021-03-12 09:58:49,550 \n",
      "Results:\n",
      "- F-score (micro): 0.9735\n",
      "- F-score (macro): 0.8872\n",
      "- Accuracy (incl. no class): 0.9735\n",
      "\n",
      "By class:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "             O     1.0000    0.9393    0.9687      2832\n",
      "           LOC     0.9884    0.9884    0.9884       518\n",
      "      LOCDESCR     0.9361    0.9798    0.9574      4890\n",
      "         TITLE     0.9748    0.9748    0.9748       951\n",
      "NEWSPAPERDESCR     0.9791    0.9846    0.9818     19487\n",
      "        HEADER     1.0000    0.2918    0.4518       233\n",
      "\n",
      "      accuracy                         0.9735     28911\n",
      "     macro avg     0.9797    0.8598    0.8872     28911\n",
      "  weighted avg     0.9741    0.9735    0.9720     28911\n",
      "\n",
      "2021-03-12 09:58:49,551 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.9735,\n",
       " 'dev_score_history': [0.7984,\n",
       "  0.773,\n",
       "  0.8169,\n",
       "  0.9162,\n",
       "  0.9182,\n",
       "  0.9147,\n",
       "  0.9729,\n",
       "  0.9673,\n",
       "  0.9764,\n",
       "  0.9816],\n",
       " 'train_loss_history': [1521.8027801513672,\n",
       "  790.8784806993273,\n",
       "  592.7332916259766,\n",
       "  469.07271575927734,\n",
       "  420.642817179362,\n",
       "  343.20276811387805,\n",
       "  332.5907694498698,\n",
       "  281.66776360405817,\n",
       "  296.88750627305774,\n",
       "  236.19796583387586],\n",
       " 'dev_loss_history': [781.734375,\n",
       "  574.2696533203125,\n",
       "  351.059814453125,\n",
       "  195.12217712402344,\n",
       "  176.9423828125,\n",
       "  179.46585083007812,\n",
       "  106.96636199951172,\n",
       "  104.02349090576172,\n",
       "  85.7772445678711,\n",
       "  81.4693603515625]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "trainer.train(MODELS_PATH / f'{level}_tagger',\n",
    "              learning_rate=0.05,\n",
    "              mini_batch_size=4, # previously used value 5\n",
    "              patience=2,\n",
    "              anneal_factor=.5,\n",
    "              max_epochs=10,\n",
    "              embeddings_storage_mode='cpu',\n",
    "              monitor_test=True,\n",
    "              anneal_with_restarts=True,\n",
    "              train_with_dev=False,\n",
    "              \n",
    "              )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-12 09:13:29,919 loading file /deezy_datadrive/kaspar-playground/npd/Models/lemmas_tagger/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "# first go to Load corpus section\n",
    "classifier = SequenceTagger.load(MODELS_PATH / f'{level}_tagger' / 'best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9329\t0.9392\t0.9360\n"
     ]
    }
   ],
   "source": [
    "result, score = classifier.evaluate(corpus.test, out_path = MODELS_PATH / f'{level}_tagger' / \"predictions.txt\")\n",
    "print(result.log_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(MODELS_PATH / f'{level}_tagger' / \"predictions.txt\",header=None,sep=' ')\n",
    "#predictions = predictions[predictions[1].isin(['ANIMATE','INANIMATE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [y for y in list(predictions[1])]\n",
    "y_pred = [y for y in list(predictions[2])]\n",
    "print(classification_report(y_true,y_pred,labels=['LOC','LOCDESCR','NEWSPAPERDESCR','TITLE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [25, 50,150] #,20  \n",
    "c1_param = [0.1,0.01,0.0001] # 0.1,  # ,0.00001\n",
    "c2_param = [0.1,0.01,0.0001] # 0.1, ,0.00001\n",
    "max_iter_param = [100,200]\n",
    "hyperparameters = product(context,c1_param,c2_param,max_iter_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda ll: [i for l in ll for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = [[t.text for t in s] for s in corpus.train.dataset.sentences] # other flair version requires corpus.train.dataset.dataset.sentences\n",
    "y_train = [[t.get_tag(level).value for t in s] for s in corpus.train.dataset.sentences]\n",
    "\n",
    "train = train + [[t.text for t in s] for s in corpus.dev.dataset.sentences]\n",
    "y_train = y_train + [[t.get_tag(level).value for t in s] for s in corpus.dev.dataset.sentences]\n",
    "test = [[t.text for t in s] for s in corpus.test.dataset.sentences]\n",
    "y_test_nested = [[t.get_tag(level).value for t in s] for s in corpus.test.dataset.sentences]\n",
    "y_test = flatten(y_test_nested)\n",
    "print(len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = lambda x: x.split(\"-\")[-1]\n",
    "clip_bioes = True\n",
    "if clip_bioes:\n",
    "    y_test = [clip(y) for y in y_test]\n",
    "    y_train = [[clip(y) for y in l] for l in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_nested = [[clip(i) for i in yn] for yn in y_test_nested]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "model_path = str(MODELS_PATH / f'{level}_crf.model')\n",
    "\n",
    "to_X = defaultdict(dict)\n",
    "f1_score_max = 0.0\n",
    "\n",
    "try:\n",
    "    for con,c_1,c_2,max_iter in hyperparameters:\n",
    "    \n",
    "        if not con in to_X:\n",
    "            vectorizer = SequenceVectorizer(context=con)\n",
    "            to_X[con][\"train\"] = vectorizer.transform(train)\n",
    "            to_X[con][\"test\"] = vectorizer.transform(test)\n",
    "    \n",
    "        X_train = to_X[con][\"train\"]\n",
    "        X_test = to_X[con][\"test\"]\n",
    "    \n",
    "        trainer = pycrfsuite.Trainer(verbose=False)\n",
    "    \n",
    "        params = {'c1': c_1,   # coefficient for L1 penalty\n",
    "                  'c2': c_2,  # coefficient for L2 penalty\n",
    "                  'max_iterations': max_iter,  # stop earlier\n",
    "                  'feature.possible_transitions': False\n",
    "                  }\n",
    "    \n",
    "        trainer.set_params(params)\n",
    "        for feat,labels in zip(X_train, y_train):\n",
    "            trainer.append(feat,labels)\n",
    "        trainer.train(model_path)\n",
    "    \n",
    "        tagger = pycrfsuite.Tagger()\n",
    "        tagger.open(model_path)\n",
    "        \n",
    "        y_pred = []\n",
    "        for sent in X_test:\n",
    "            y_pred.extend(tagger.tag(sent))\n",
    "            \n",
    "        print(len(y_test),len(y_pred))\n",
    "        \n",
    "        for t in [\"micro\",\"macro\",\"weighted\"]:\n",
    "            exec(f\"f_{t} =  f1_score(y_test,y_pred,average='{t}',labels=['HEADER','LOC','LOCDESCR','NEWSPAPERDESCR','TITLE'])\")\n",
    "        \n",
    "        print(\"Best macro f1 score, %.3f\"%f1_score_max)\n",
    "        print(\"Current macro f1 score, %.3f\"%f_macro)\n",
    "        \n",
    "        if f_macro > f1_score_max:\n",
    "            best_params = [con,c_1,c_2,max_iter]\n",
    "            f1_score_max = f_macro\n",
    "            cl_r = classification_report(y_pred,y_test)\n",
    "            \n",
    "        results[(con,c_1,c_2,max_iter)] = [f_micro,f_macro,f_weighted]\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Stopping early.')\n",
    "\n",
    "print('Done.')\n",
    "print(best_params)\n",
    "print(\"Best macro f1 score, %.3f\"%f1_score_max)\n",
    "print(cl_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = str(MODELS_PATH / f'{level}_crf-final.model')\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "params = {'c1': 0.01,   # coefficient for L1 penalty\n",
    "          'c2': 0.01,  # coefficient for L2 penalty\n",
    "          'max_iterations': 100,  # stop earlier\n",
    "                  }\n",
    "\n",
    "context = 25\n",
    "trainer.set_params(params)\n",
    "\n",
    "vectorizer = SequenceVectorizer(context=context)\n",
    "data = [[t.text for t in s] for s in corpus.train.dataset.sentences] + \\\n",
    "        [[t.text for t in s] for s in corpus.dev.dataset.sentences] + \\\n",
    "            [[t.text for t in s] for s in corpus.test.dataset.sentences]\n",
    "X = vectorizer.transform(data)\n",
    "y = y_train + y_test_nested\n",
    "\n",
    "print(len(data),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat,labels in zip(X, y):\n",
    "    trainer.append(feat,labels)\n",
    "trainer.train(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params['context'] = context\n",
    "\n",
    "with  open(MODELS_PATH / f'{level}_crf-final.params','wb') as out_pickle:\n",
    "    pickle.dump(params,out_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
